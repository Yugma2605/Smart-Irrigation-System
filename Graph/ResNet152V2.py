acc = [0.3191489279270172, 0.35638296604156494, 0.3882978856563568, 0.38297873735427856, 0.44680851697921753, 0.44680851697921753, 0.41489362716674805, 0.47340425848960876, 0.478723406791687, 0.5319148898124695, 0.6223404407501221, 0.8191489577293396, 0.8617021441459656, 0.9308510422706604, 0.9255319237709045, 0.9468085169792175, 0.9521276354789734, 0.9734042286872864, 0.9627659320831299, 0.9734042286872864, 0.9946808218955994, 0.978723406791687, 0.9946808218955994, 0.9840425252914429, 1.0, 0.9893617033958435, 1.0, 0.9840425252914429, 1.0, 1.0, 1.0]
val_acc = [0.3870967626571655, 0.4516128897666931, 0.4838709533214569, 0.5161290168762207, 0.5329032373428345, 0.5483871102333069, 0.5506451439857483, 0.5093548262119293, 0.4838709533214569, 0.5806451439857483, 0.8709677457809448, 0.8709677457809448, 0.9354838728904724, 0.8387096524238586, 0.9677419066429138, 0.9677419066429138, 1.0, 0.9677419066429138, 0.9677419066429138, 0.9032257795333862, 0.9677419066429138, 0.9677419066429138, 0.9354838728904724, 0.9677419066429138, 0.9677419066429138, 1.0, 0.9677419066429138, 1.0, 1.0, 1.0, 1.0]
loss = [1.0183793306350708, 0.9668335318565369, 0.9411848187446594, 0.8934248089790344, 0.8334548473358154, 0.832065999507904, 0.8317341208457947, 0.8046047687530518, 0.7653800249099731, 0.7102538347244263, 0.6097682118415833, 0.41257601976394653, 0.3158821761608124, 0.19040215015411377, 0.17983025312423706, 0.12245465070009232, 0.09937617182731628, 0.06457339972257614, 0.09641920030117035, 0.06275110691785812, 0.022430988028645515, 0.08697906136512756, 0.01721002906560898, 0.02018534392118454, 0.008621602319180965, 0.022993307560682297, 0.003098581451922655, 0.039344482123851776, 0.002689850516617298, 0.006738835945725441, 0.006339441519230604]
val_loss = [0.8965660929679871, 0.8247435688972473, 0.8033365607261658, 0.7686339616775513, 0.6600515842437744, 0.720047116279602, 0.6727350950241089, 0.724307656288147, 0.7395349144935608, 0.6719841361045837, 0.41223809123039246, 0.3146854043006897, 0.2264716476202011, 0.2823929190635681, 0.14029617607593536, 0.17500928044319153, 0.03044954128563404, 0.13269184529781342, 0.10638769716024399, 0.16270940005779266, 0.05784774571657181, 0.054694775491952896, 0.12390616536140442, 0.11936432868242264, 0.04080946370959282, 0.019711429253220558, 0.04829774424433708, 0.03466056287288666, 0.03825924172997475, 0.031342167407274246, 0.0069104344584047794]

import matplotlib.pyplot as plt
initial_epochs = 10
plt.figure(figsize=(8, 8))
plt.subplot(2, 1, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.ylim([0.2, 1.1])
plt.plot([initial_epochs-1,initial_epochs-1],
          plt.ylim(), label='Start Fine Tuning')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(2, 1, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.ylim([-0.1, 1.0])
plt.plot([initial_epochs-1,initial_epochs-1],
         plt.ylim(), label='Start Fine Tuning')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.xlabel('epoch')
plt.show()